from pathlib import Path
import pandas as pd
import re
import shutil
# The main entry point of your workflow.
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.

report: "report/workflow.rst"

# Allow users to fix the underlying OS via singularity.
#singularity: "docker://votti/miniconda3mamba:v0.4.2"
conda: 'envs/env_base.yaml'

# Input
remote_fol_path_base=Path('/home/vitoz/Data/SegData/basel_zuri')
remote_file_path_ilp= remote_fol_path_base / '20171130_pixelclassification_BaselZuri.ilp'
remote_file_path_panel= remote_fol_path_base / 'panel.csv'
remote_fol_path_ome= remote_fol_path_base / 'ome_all'
remote_fol_path_cpproj = remote_fol_path_base / '20191211_analysis_HubMAP_LN_Spleen_thymus.cpproj'

# Not used yet:
remote_fol_path_atiffs= remote_fol_path_base / 'analysis'
remote_fol_path_ilastikcrops= remote_fol_path_base / 'ilastik_random_combined'

# Optional input
fol_path_resources = Path('resources')
fn_manual_crop_coordinates = fol_path_resources / 'manual_coordinates.csv'

# Regular expressions to extract data from crop filenames
suffix_ilastik= "ilastik2"
re_label_basic = "(?P<cropname>.*)_label\.tiff"
re_label_crop = f"(?P<basename>.*)_{suffix_ilastik}_(?P<suffix>.*)"
re_label_suffix = "l(?P<cropnr>[0-9]+)_x(?P<x>[0-9]+)_y(?P<y>[0-9]+)"


# Output
fol_path_results = Path('results')

file_path_ilp = fol_path_results / 'ilatik_trained.ilp'
file_path_panel = fol_path_results / 'panel.csv'
fol_path_ome = fol_path_results / 'ome'

fol_path_training=fol_path_results / 'training_images'
file_pat_training_imgs = fol_path_training / '{cropname}.tiff'
fol_path_labels=fol_path_results / 'training_labels'
file_path_ilp_features=fol_path_results / 'feature_matrix.txt'
file_path_cp_seg=fol_path_results / 'cellsegmentation.cpproj'
file_path_labelmeta= fol_path_results / 'training_image_meta.csv'

_training_meta = None
def get_labelmeta():
    checkpoints.get_training_cropmeta.get()
    if _training_meta is not None:
        return _training_meta
    else:
        return pd.read_csv(file_path_labelmeta)


def get_cropnames(wildcards):
    cropnames = get_labelmeta()['cropname'].values
    return expand(file_pat_training_imgs, cropname=cropnames)

rule all:
    input:
        fol_path_labels, file_path_ilp_features, file_path_labelmeta,
         fol_path_ome, file_path_panel
        # The first rule should define the default target files
        # Subsequent target rules can be specified below. They should start with all_*.

rule extract_training_labels:
    input:
          file_path_ilastik=file_path_ilp
    output:
          fol_path_labels=directory(fol_path_labels)
    conda: 'envs/env_base.yaml'
    shell:
         'python workflow/scripts/extract_from_ilp.py extract_labels {input.file_path_ilastik} {output.fol_path_labels}'

rule extract_feature_matrix:
    input:
         file_path_ilastik=file_path_ilp
    output:
         file_path_ilp_features
    conda: 'envs/env_base.yaml'
    shell:
         'python workflow/scripts/extract_from_ilp.py extract_feature_matrix '
         '{input.file_path_ilastik} {output[0]}'

rule get_training_images:
    input:
        remote_fol_path_ilastikcrops / '{cropname}.tiff'
    output:
        fol_path_training / '{cropname}.tiff'
    run:
        shutil.copy(input[0], output[0])


checkpoint get_training_cropmeta:
    # TODO: Move into helper function
    input:
        fol_labels=fol_path_labels
    output:
        fn_cropmeta=file_path_labelmeta
    params:
        re_basic=re_label_basic,
        re_crop=re_label_crop,
        re_suffix=re_label_suffix,
        fn_manual_coordinates=fn_manual_crop_coordinates
    run:
        re_basic = re.compile(params.re_basic)
        re_crop = re.compile(params.re_crop)
        re_suffix = re.compile(params.re_suffix)
        fol_labs = Path(input.fol_labels)
        file_dict = {fp.name: re_basic.match(fp.name).groupdict()
            for fp in fol_labs.glob('*_label.tiff')}
        for fn, dic in file_dict.items():
            crop_match = re_crop.match(dic['cropname'])
            if crop_match is None:
                raise ValueError(fn)

            dic.update(**crop_match.groupdict())
            suffix_match = re_suffix.match(dic['suffix'])
            if suffix_match is None:
                raise ValueError(fn)
            dic.update(**suffix_match.groupdict())
            dic['filename'] = fn
        fn_manual_coordinates = Path(params.fn_manual_coordinates)
        dat_crops = pd.DataFrame(file_dict).T
        if fn_manual_coordinates.exists():
            dat_m_crops = pd.read_csv(fn_manual_crop_coordinates)
            dat_crops['coord_origin'] = 'name'
            dat_m_crops['coord_origin'] = 'matching'
            dat_crops = dat_crops.set_index('basename', drop=False)
            dat_m_crops = dat_m_crops.set_index('basename', drop=False)
            dat_crops.update(dat_m_crops, overwrite=True)
        dat_crops.to_csv(output.fn_cropmeta, index=False)



# Retrieve from remote
rule get_ilp:
    input: remote_file_path_ilp
    output: file_path_ilp
    shell:
         """
         rsync {input[0]} {output[0]}
         """


rule get_panel:
    input: remote_file_path_panel
    output: file_path_panel
    shell:
         """
         rsync {input[0]} {output[0]}
         """

rule get_ome:
    input: remote_fol_path_ome
    output: directory(fol_path_ome)
    shell:
         """
         mkdir {output[0]}
         rsync {input[0]}/* {output[0]}
         """
